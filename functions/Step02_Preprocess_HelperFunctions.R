library(synapser)
library(Seurat)
library(reshape2)
library(stringr)
library(GEOquery)
library(reticulate)
library(HDF5Array)
library(dplyr)
library(readxl)
library(SingleCellExperiment)
library(sageRNAUtils)
library(scDblFinder)

source("Filenames.R")

# Generic helper functions -----------------------------------------------------------

# Assumes you have already authenticated a Synapse login or have a Synapse
# config set up with proper credentials
DownloadFromSynapse <- function(synIDs, downloadLocation) {
  synLogin()
  files <- list()

  for (name in names(synIDs)) {
    files[[name]] <- synGet(synIDs[[name]]$id,
                            version = synIDs[[name]]$version,
                            downloadLocation = downloadLocation)
  }

  return(files)
}

# Standardize cell type names across all data sets.
RemapCelltypeNames <- function(celltypes) {
  # Use only the first 2 characters (reduces the number of possible variations)
  celltypes_mod <- str_to_lower(str_sub(celltypes, end = 2))

  remap <- melt(list(Astrocyte = c("as"),
                     Endothelial = c("en"),
                     Excitatory = c("ex", "gl"), # gl = Glut
                     Inhibitory = c("in", "ga"), # ga = GABA
                     Microglia = c("mg", "mi"),
                     Oligodendrocyte = c("od", "ol"),
                     OPC = c("op"),
                     Pericyte = c("pe"),
                     VLMC = c("vl")))
  rownames(remap) <- remap$value

  return(remap[celltypes_mod, "L1"])
}

# Use the gene conversion list from Step01 to get the mapping between Ensembl ID
# and gene symbol
EnsemblIdToGeneSymbol <- function(gene_list) {
  gene_conversions <- read.csv(file_gene_list)

  rownames(gene_conversions) <- gene_conversions$ensembl_gene_id
  overlap <- intersect(gene_list, gene_conversions$ensembl_gene_id)

  gene_conversions <- gene_conversions[overlap, ]

  genes <- gene_conversions %>%
    dplyr::select(ensembl_gene_id, canonical_symbol, gene_length) %>%
    dplyr::rename(hgnc_symbol = canonical_symbol) %>%
    dplyr::arrange(ensembl_gene_id)
  return(genes)
}

# We have single cell data sets that were aligned to different versions of
# GRCh 38 and have different symbols for the same genes. This function maps
# old symbols to new ones based on the gene list generated by Step01
UpdateGeneSymbols <- function(dataset, gene_list) {
  version <- switch(dataset,
                    "cain" = "symbol_v98",
                    "lau" = "symbol_v93",
                    "leng" = "symbol_v84",
                    "mathys" = "symbol_Mathys", # They provided their mapping as a file
                    "seaRef" = "symbol_seaRef")

  gene_conversions <- read.csv(file_gene_list)
  gene_conversions$original_symbol <- gene_conversions[, version]

  genes <- subset(gene_conversions, original_symbol %in% gene_list)
  rownames(genes) <- make.unique(genes$original_symbol, sep = "/")

  genes <- genes[rownames(genes) %in% gene_list, ] |>
    dplyr::select(ensembl_gene_id, canonical_symbol, original_symbol) |>
    dplyr::rename(hgnc_symbol = canonical_symbol) |>
    dplyr::arrange(ensembl_gene_id)

  return(genes)
}


# Generic functions that call dataset-specific functions ----------------------

DownloadData <- function(dataset, metadata_only = FALSE) {
  files <- switch(dataset,
                  "cain" = DownloadData_Cain(metadata_only),
                  "lau" = DownloadData_Lau(metadata_only),
                  "leng" = DownloadData_Leng(metadata_only),
                  "mathys" = DownloadData_Mathys(metadata_only),
                  "seaRef" = DownloadData_SEARef(metadata_only),
                  "Mayo" = DownloadData_Mayo(metadata_only),
                  "MSBB" = DownloadData_MSBB(metadata_only),
                  "ROSMAP" = DownloadData_ROSMAP(metadata_only))
  return(files)
}

ReadMetadata <- function(dataset, files) {
  metadata <- switch(dataset,
                     "cain" = ReadMetadata_Cain(files),
                     "lau" = ReadMetadata_Lau(files),
                     "leng" = ReadMetadata_Leng(files),
                     "mathys" = ReadMetadata_Mathys(files),
                     "seaRef" = ReadMetadata_SEARef(files),
                     "Mayo" = ReadMetadata_BulkData(dataset, files),
                     "MSBB" = ReadMetadata_BulkData(dataset, files),
                     "ROSMAP" = ReadMetadata_BulkData(dataset, files))
  return(metadata)
}

ReadCovariates <- function(dataset, files) {
  covariates <- switch(dataset,
                       "cain" = ReadMetadata_Cain(files)$covariates,
                       "lau" = ReadCovariates_Lau(files),
                       "leng" = ReadMetadata_Leng(files)$covariates,
                       "mathys" = ReadMetadata_Mathys(files)$covariates,
                       "seaRef" = ReadMetadata_SEARef(files)$covariates,
                       "Mayo" = ReadMetadata_BulkData(dataset, files)$covariates,
                       "MSBB" = ReadMetadata_BulkData(dataset, files)$covariates,
                       "ROSMAP" = ReadMetadata_BulkData(dataset, files)$covariates)
  return(covariates)
}

ReadCounts <- function(dataset, files) {
  counts <- switch(dataset,
                   "cain" = ReadCounts_Cain(files),
                   "lau" = ReadCounts_Lau(files),
                   "leng" = ReadCounts_Leng(files),
                   "mathys" = ReadCounts_Mathys(files),
                   "seaRef" = ReadCounts_SEARef(files),
                   "Mayo" = ReadCounts_BulkData(files),
                   "MSBB" = ReadCounts_BulkData(files),
                   "ROSMAP" = ReadCounts_ROSMAP(files))
  return(counts)
}


# Custom functions for each data set ------------------------------------------


## Cain, et al., 2020 [preprint] -----------------------------------------------
# https://doi.org/10.1101/2020.12.22.424084

DownloadData_Cain <- function(metadata_only = FALSE) {
  synIDs <- list("metadata" = list(id = "syn23554294", version = 5),
                 "biospecimen_metadata" = list(id = "syn21323366", version = 17),
                 "clinical_metadata" = list(id = "syn3191087", version = 11),
                 "counts" = list(id = "syn23554292", version = 3),
                 "genes" = list(id = "syn23554293", version = 2))

  if (metadata_only) {
    synIDs <- synIDs[1:3]
  }

  files <- DownloadFromSynapse(synIDs, dir_cain_raw)
  return(files)
}

ReadMetadata_Cain <- function(files) {
  metadata <- read.csv(files$metadata$path)

  # Diagnosis is in the specimen ID for each donor
  dx_defs <- c("Cdx1-pAD0" = "Control",
               "Cog1-Path0" = "Control",
               "Cdx1-pAD1" = "Control w/ Pathology",
               "Cog1-Path1" = "Control w/ Pathology",
               "Cdx4-pAD0" = "Non-AD Dementia",
               "Cog4-Path0" = "Non-AD Dementia",
               "Cdx4-pAD1" = "AD",
               "Cog4-Path1" = "AD")

  tmp <- as.data.frame(str_split(metadata$specimenID, "-", simplify = TRUE))
  tmp <- paste(tmp$V4, tmp$V5, sep = "-")

  metadata$diagnosis <- dx_defs[tmp]

  metadata$Cell.Type <- RemapCelltypeNames(metadata$Cell.Type)

  # Fix the 'no.clus' label for sub.cluster
  no_clust <- metadata$sub.cluster == "no.clus"
  metadata$sub.cluster[no_clust] <- metadata$Cell.Type[no_clust]

  # Assign oligodendrocyte subtypes based on the oligodendrocyte 'topic weights'
  # in the metadata. The paper notes that oligo subtypes are more of a spectrum
  # than discrete subtypes, however for our purposes we partition into discrete
  # subtypes by using the highest-weighted 'topic'.
  cols <- paste0("oligodendrocytes.topicweight.", 1:4)
  oligos <- which(metadata$Cell.Type == "Oligodendrocyte")
  olig_types <- apply(metadata[oligos, cols], 1, which.max)
  metadata$sub.cluster[oligos] <- paste0("Oligo.", olig_types)

  metadata <- metadata[, c("cell_name", "specimenID", "diagnosis",
                           "Cell.Type", "sub.cluster")]

  biospecimen <- read.csv(files$biospecimen_metadata$path)
  biospecimen <- subset(biospecimen, specimenID %in% metadata$specimenID) %>%
    select(individualID, specimenID)

  clinical <- read.csv(files$clinical_metadata$path)
  clinical <- subset(clinical, individualID %in% biospecimen$individualID)
  clinical <- merge(clinical, biospecimen, by = "individualID") %>%
    dplyr::rename(sample = specimenID)

  # Fix age fields to be numeric
  clinical$age_death[clinical$age_death == "90+"] <- 90
  clinical$age_death <- as.numeric(clinical$age_death)
  clinical$age_at_visit_max[clinical$age_at_visit_max == "90+"] <- 90
  clinical$age_at_visit_max <- as.numeric(clinical$age_at_visit_max)

  return(list("metadata" = metadata, "covariates" = clinical))
}

ReadCounts_Cain <- function(files) {
  counts <- ReadMtx(mtx = files$counts$path,
                    cells = files$metadata$path,
                    features = files$genes$path,
                    feature.column = 1,
                    skip.cell = 1,
                    skip.feature = 1)

  # The column names and genes don't get read in correctly by ReadMtx because
  # the input csvs aren't formatted as expected for MTX
  colnames(counts) <- str_replace(colnames(counts), ",.*", "")
  rownames(counts) <- str_replace(rownames(counts), ".*,", "")

  return(counts)
}

QC_Cain <- function(seurat) {
  # This data has already been thresholded by counts and doesn't need additional
  # modification.
  return(seurat)
}


## Lau, et al., 2020 -----------------------------------------------------------
# https://doi.org/10.1073/pnas.2008762117

DownloadData_Lau <- function(metadata_only = FALSE) {
  gse <- getGEO("GSE157827", destdir = dir_lau_raw)

  geo_metadata <- pData(phenoData(gse[[1]]))
  file_geo_metadata <- file.path(dir_lau_raw, "geo_metadata.csv")
  write.csv(geo_metadata, file_geo_metadata)

  if (!metadata_only) {
    geo <- getGEOSuppFiles(GEO = "GSE157827", makeDirectory = FALSE,
                           baseDir = dir_lau_raw)
    untar(rownames(geo)[1], exdir = dir_lau_raw)
  }

  synIDs <- list("clinical_metadata" = list(id = "syn52308080", version = 1))

  files <- DownloadFromSynapse(synIDs, dir_lau_raw)

  files[["geo_metadata"]] <- file_geo_metadata
  return(files)
}

ReadMetadata_Lau <- function(files) {
  # We have to get the barcodes from individual files
  geo_metadata <- read.csv(files$geo_metadata, row.names = 1) %>%
    select(title, diagnosis.ch1) %>%
    dplyr::rename(sample = title, diagnosis = diagnosis.ch1)

  barcode_files <- list.files(path = dir_lau_raw, pattern = "barcodes",
                              full.names = TRUE)
  barcodes <- lapply(barcode_files, function(filename) {
    bc <- read.table(gzfile(filename)) %>% dplyr::rename(barcode = V1)
    file_info <- str_split(filename, pattern = "/", simplify = TRUE)
    file_info <- str_split(file_info[, length(file_info)],
                           pattern = "_",
                           simplify = TRUE)
    bc$sample <- file_info[, 2]
    bc$barcode <- paste(bc$barcode, bc$sample, sep = "_")
    return(bc)
  })

  metadata <- do.call(rbind, barcodes) %>%
    merge(geo_metadata, by = "sample") %>%
    select(barcode, sample, diagnosis)

  # This data set doesn't come with pre-labeled cells
  metadata$broad_class <- NA
  metadata$sub_class <- NA

  clinical <- ReadCovariates_Lau(files)

  return(list("metadata" = metadata, "covariates" = clinical))
}

ReadCovariates_Lau <- function(files) {
  clinical <- readxl::read_excel(files$clinical_metadata$path, sheet = "Patient_info")
  clinical <- as.data.frame(clinical) %>% dplyr::rename(sample = ID)
  return(clinical)
}

ReadCounts_Lau <- function(files) {
  geo_metadata <- read.csv(files$geo_metadata, row.names = 1)
  samples <- rownames(geo_metadata)
  counts_list <- list()

  for (sample in samples) {
    files <- list.files(path = dir_lau_raw,
                        pattern = paste0(sample, "_.*\\.gz"),
                        full.names = TRUE)

    matrix_file <- grep("matrix", files, value = TRUE)
    barcodes_file <- grep("barcodes", files, value = TRUE)
    features_file <- grep("features", files, value = TRUE)

    counts <- ReadMtx(mtx = matrix_file,
                      cells = barcodes_file,
                      features = features_file)
    colnames(counts) <- paste(colnames(counts),
                              geo_metadata[sample, "title"],
                              sep = "_")

    counts_list[[sample]] <- counts
  }

  # Make sure all counts are in the same gene order
  genes <- unique(unlist(lapply(counts_list, rownames)))
  counts_list <- lapply(counts_list, function(X) {
    X[genes, ]
  })

  counts <- do.call(cbind, counts_list)

  return(counts)
}

QC_Lau <- function(seurat) {
  # We need to threshold on total counts / detected genes after removal of doublets
  seurat$high_expression <- seurat$nCount_RNA > 25000
  seurat$low_expression <- seurat$nFeature_RNA < 400

  seurat$pass_QC <- seurat$pass_QC &
    !seurat$high_expression &
    !seurat$low_expression

  return(seurat)
}


## Leng, et al., 2021 ----------------------------------------------------------
# https://doi.org/10.1038/s41593-020-00764-7

# metadata_only is an unused variable for this dataset as the metadata is
# embedded in the counts RDS files
DownloadData_Leng <- function(metadata_only = FALSE) {
  synIDs <- list("counts_ec" = list(id = "syn22722817", version = 1),
                 "counts_sfg" = list(id = "syn22722860", version = 1))
  files <- DownloadFromSynapse(synIDs, dir_leng_raw)
  return(files)
}

ReadMetadata_Leng <- function(files) {
  sce_ec <- readRDS(files$counts_ec$path)
  sce_sfg <- readRDS(files$counts_sfg$path)

  metadata <- rbind(colData(sce_ec), colData(sce_sfg))

  braak <- list("0" = "Control",
                "2" = "Early Pathology",
                "6" = "AD")

  metadata$cell_id <- rownames(metadata)
  metadata$diagnosis <- unlist(braak[metadata$BraakStage])
  metadata$sub_cluster <- str_replace(metadata$clusterAssignment, "EC:|SFG:", "")

  metadata <- as.data.frame(metadata)

  covariates <- metadata %>%
    select(SampleID, PatientID, BrainRegion, BraakStage, SampleBatch, diagnosis) %>%
    distinct() %>%
    dplyr::rename(sample = SampleID)

  metadata <- metadata %>%
    select(cell_id, SampleID, diagnosis, clusterCellType, sub_cluster)

  return(list("metadata" = metadata, "covariates" = covariates))
}

ReadCounts_Leng <- function(files) {
  sce_ec <- readRDS(files[["counts_ec"]]$path)
  sce_sfg <- readRDS(files[["counts_sfg"]]$path)

  # Both counts matrices have the same genes in the same order already
  return(cbind(counts(sce_ec), counts(sce_sfg)))
}

QC_Leng <- function(seurat) {
  # This data has really low counts in general so the cap for high expression
  # is fairly low too
  seurat$high_expression <- seurat$nCount_RNA > 10000
  seurat$pass_QC <- seurat$pass_QC & !seurat$high_expression

  return(seurat)
}


## Mathys, et al., 2019 --------------------------------------------------------
# http://dx.doi.org/10.1038/s41586-019-1195-2

DownloadData_Mathys <- function(metadata_only = FALSE) {
  synIDs <- list("clinical_metadata" = list(id = "syn3191087", version = 11),
                 "cell_metadata" = list(id = "syn18686383", version = 1),
                 "counts" = list(id = "syn18687958", version = 1),
                 "genes" = list(id = "syn18687959", version = 1))

  if (metadata_only) {
    synIDs <- synIDs[1:2]
  }

  files <- DownloadFromSynapse(synIDs, dir_mathys_raw)
  return(files)
}

ReadMetadata_Mathys <- function(files) {
  clinical <- read.csv(files$clinical_metadata$path)
  cellMeta <- read.table(files$cell_metadata$path, sep = "\t", header = TRUE)
  metadata <- merge(cellMeta, clinical,
                    by = "projid", all.x = TRUE, all.y = FALSE)

  # See https://www.synapse.org/#!Synapse:syn3191090 for this information (cogdx)
  diagnosis.codes <- list("1" = "Control",
                          "2" = "MCI",
                          "3" = "MCI",
                          "4" = "AD",
                          "5" = "AD",
                          "6" = "Other")
  diagnosis.codes <- melt(diagnosis.codes)
  colnames(diagnosis.codes) <- c("diagnosis", "cogdx")

  metadata <- merge(metadata, diagnosis.codes, by = "cogdx")

  # Remove cells from the one sample with an "Other" diagnosis
  metadata <- subset(metadata, diagnosis != "Other")

  covariates <- metadata[, c(colnames(clinical), "diagnosis")] %>%
    distinct() %>%
    dplyr::rename(sample = projid)

  # Fix age fields to be numeric
  covariates$age_death[covariates$age_death == "90+"] <- 90
  covariates$age_death <- as.numeric(covariates$age_death)
  covariates$age_at_visit_max[covariates$age_at_visit_max == "90+"] <- 90
  covariates$age_at_visit_max <- as.numeric(covariates$age_at_visit_max)

  metadata <- metadata %>% select(TAG, projid, diagnosis)
  metadata$broad_class <- NA
  metadata$sub_class <- NA

  return(list("metadata" = metadata, "covariates" = covariates))
}

ReadCounts_Mathys <- function(files) {
  counts <- ReadMtx(mtx = files$counts$path,
                    cells = files$cell_metadata$path,
                    features = files$genes$path,
                    feature.column = 1, skip.cell = 1)
  return(counts)
}

QC_Mathys <- function(seurat) {
  seurat$high_expression <- seurat$nCount_RNA > 25000
  seurat$pass_QC <- seurat$pass_QC &
    !seurat$high_expression

  return(seurat)
}


## Seattle Reference Atlas -----------------------------------------------------
# Reference data set (5 donors): https://portal.brain-map.org/atlases-and-data/rnaseq/human-mtg-10x_sea-ad
# Full data set (84 donors): https://portal.brain-map.org/explore/seattle-alzheimers-disease/seattle-alzheimers-disease-brain-cell-atlas-download?edit&language=en
# Metadata: https://www.synapse.org/#!Synapse:syn28256462

# These files are h5ad (AnnData) files. I read the metadata part in with
# reticulate and the "anndata" package, which handles all the categorical
# renaming from the file.
# However, the easiest way to get the data matrix is to use the HDF5Array
# package instead of reticulate. We can't use the R packages that read in
# AnnData (zellkonverter or anndata) because they clobber something from the
# synapser package that makes it not work right.

# metadata_only is an unused variable for this data set, as we need to download
# the data to access the metadata in the anndata file.
DownloadData_SEARef <- function(metadata_only = FALSE) {
  synIDs <- list("individual_metadata" = list(id = "syn31149116", version = 5))
  files <- DownloadFromSynapse(synIDs, downloadLocation = dir_seaad_raw)

  files[["counts"]] <- file_searef_h5

  if (!file.exists(files[["counts"]]) & !metadata_only) { # Don't re-download, this file is large
    download.file(url_searef_h5, destfile = files[["counts"]], method = "curl")
  }

  return(files)
}

ReadMetadata_SEARef <- function(files) {
  donor_metadata <- read.csv(files$individual_metadata$path, row.names = 1)

  ad <- import("anndata")
  adata <- ad$read_h5ad(files$counts, backed = "r")

  metadata <- adata$obs
  metadata <- merge(metadata, donor_metadata,
                    by.x = "external_donor_name_label",
                    by.y = "individualID")

  metadata <- metadata |>
    select(
      sample_name, external_donor_name_label, diagnosis, class_label,
      subclass_label, cluster_label, class_confidence, subclass_confidence,
      cluster_confidence
    ) |>
    dplyr::rename(supertype = cluster_label,
                  supertype_confidence = cluster_confidence)

  covariates <- subset(donor_metadata,
                       individualID %in% metadata$external_donor_name_label) %>%
    dplyr::rename(sample = individualID)

  covariates$ageDeath <- as.numeric(covariates$ageDeath)

  return(list("metadata" = metadata, "covariates" = covariates))
}

ReadCounts_SEARef <- function(files) {
  counts <- H5ADMatrix(files$counts)

  col_names <- as.character(HDF5Array(files$counts,
                                      file.path("obs", "sample_name")))
  dimnames(counts)[[2]] <- col_names
  return(counts)
}


# Generic single cell QC function ----------------------------------------------

QC_SingleCell <- function(metadata, counts, mt_threshold = 0.05, dataset_name, n_cores = 2) {
  # The seaRef data set has already undergone extensive QC, including doublet
  # removal and removal of cells with percent_mito > 0.05%. Therefore we do not
  # remove any additional cells here.
  if (dataset_name == "seaRef") {
    return(counts)
  }

  # Seed for reproducible results with scDblFinder, based on the dataset name
  seed <- sageRNAUtils::string_to_seed(paste(dataset_name, "QC"))
  set.seed(seed)

  stats <- list(total_cells = ncol(counts))

  sce <- SingleCellExperiment(list("counts" = counts), colData = metadata)
  sce <- scuttle::addPerCellQCMetrics(sce)

  # Small amount of initial thresholding to remove empty droplets
  sce <- sce[, sce$detected > 200 & sce$sum > 200]

  stats$low_expression <- ncol(counts) - ncol(sce)

  # If any samples have > 30% of their cells with percent_mito > 0.05, remove
  # them as potentially poor quality samples. The 30% threshold was determined
  # by visually inspecting the distribution of percent_mito for each sample in
  # each dataset and choosing a threshold that removed the most obviously skewed
  # samples in all datasets.
  # TODO: For Lau, this removes 4 AD and 2 NC samples. Lowering to 0.2 removes 2 more AD samples
  # TODO: For Leng, this removes 1 EC sample. Lowering to 0.2 removes 2 SFG samples
  # TODO: For Mathys, this removes 18 samples. Lowering to 0.2 removes 2 more samples.
  mito_stats <- table(sce$sample, sce$percent_mito > mt_threshold)
  mito_stats <- sweep(mito_stats, 1, rowSums(mito_stats), "/")

  if (ncol(mito_stats) == 2) {
    stats$removed_samples <- names(which(mito_stats[, "TRUE"] > 0.3))
    stats$removed_sample_cells <- sum(sce$sample %in% stats$removed_samples)
  } else {
    # This happens with cain, no samples need to be removed
    stats$removed_samples <- c()
    stats$removed_sample_cells <- 0
  }

  if (length(stats$removed_samples) > 0) {
    cat(str_glue("Removing {length(stats$removed_samples)} sample(s) due to ",
                 "sample-wide high mitochondrial gene expression:"),
        paste(stats$removed_samples, collapse = ", "), "\n")
  }

  sce <- sce[, !(sce$sample %in% stats$removed_samples)]

  cat("Finding doublets...\n")

  sce <- scDblFinder::scDblFinder(
    sce,
    clusters = TRUE,
    samples = "sample",
    nfeatures = 4000,
    BPPARAM = BiocParallel::SnowParam(n_cores, RNGseed = seed)
  )

  stats$doublets <- sum(sce$scDblFinder.class == "doublet")
  stats$doublet_pct <- round(stats$doublets / stats$total_cells * 100, digits = 2)
  cat(str_glue("Found {stats$doublets} doublets ({stats$doublet_pct}% of total)."),
      "\n")

  cat("Removing doublet clusters...\n")
  seurat <- as.Seurat(sce, data = "counts")
  rm(sce)
  gc()

  seurat <- RenameAssays(seurat, assay.name = "originalexp", new.assay.name = "RNA")
  seurat <- seurat |>
    NormalizeData() |>
    FindVariableFeatures(nfeatures = 4000) |>
    ScaleData() |>
    RunPCA() |>
    FindNeighbors(dims = 1:20) |> # 20 seems good for all data sets
    FindClusters(resolution = 5)

  seurat$seurat_clusters <- paste0("C", seurat$seurat_clusters)
  dbl_stats <- table(seurat$seurat_clusters, seurat$scDblFinder.class)
  dbl_stats <- sweep(dbl_stats, 1, rowSums(dbl_stats), "/")
  dbl_clusts <- names(which(dbl_stats[, "doublet"] > 0.5))

  cat(str_glue("Removed {length(dbl_clusts)} doublet clusters."), "\n")

  seurat$singlet <- seurat$scDblFinder.class == "singlet"
  seurat$doublet_cluster <- seurat$seurat_clusters %in% dbl_clusts
  seurat$low_mito <- seurat$percent_mito < mt_threshold

  seurat$pass_QC <- seurat$singlet &
    !seurat$doublet_cluster &
    seurat$low_mito

  seurat$high_expression <- FALSE
  seurat$low_expression <- FALSE

  # Do any dataset-specific QC, which may include filtering on high/low
  # expression
  seurat <- switch(dataset_name,
                   "cain" = QC_Cain(seurat),
                   "lau" = QC_Lau(seurat),
                   "leng" = QC_Leng(seurat),
                   "mathys" = QC_Mathys(seurat))

  # Collect some final stats for printout

  # Cells that weren't marked as doublets but are in doublet clusters
  stats$doublet_cluster_cells <- sum(seurat$doublet_cluster & seurat$singlet)

  # Cells remaining with high mitochondrial expression
  stats$mito_cells <- sum(!seurat$low_mito & !seurat$doublet_cluster & seurat$singlet)

  # Cells remaining with low expression
  stats$low_expression <- stats$low_expression +
    sum(seurat$low_mito & !seurat$doublet_cluster &
          seurat$singlet & seurat$low_expression)

  # Cells remaining with high expression
  stats$high_expression <- sum(seurat$low_mito & !seurat$doublet_cluster &
                                 seurat$singlet & seurat$high_expression)

  stats$pct_pass <- round(sum(seurat$pass_QC) / ncol(counts) * 100, digits = 2)

  cat(str_glue(
    "{sum(seurat$pass_QC)} of {ncol(counts)} cells ({stats$pct_pass}%) passed ",
    "QC. Removed:\n",
    ".. {stats$removed_sample_cells} cells from {length(stats$removed_samples)} ",
    "low-quality sample(s)\n",
    ".. {stats$doublets} doublets\n",
    ".. {stats$doublet_cluster_cells} additional cells in doublet clusters\n",
    ".. {stats$low_expression} cells with low expression\n",
    ".. {stats$high_expression} cells with high expression\n",
    ".. {stats$mito_cells} cells with high mitochondrial expression"
  ), "\n")

  # Save stats for examination
  saveRDS(stats, file.path(dir_tmp, str_glue("{dataset_name}_qc.rds")))

  # Only keep cells that passed QC
  return(counts[, colnames(seurat)[seurat$pass_QC]])
}


## Mayo ------------------------------------------------------------------------
# Bulk RNA seq data from the Mayo RNA Seq Study:
# https://adknowledgeportal.synapse.org/Explore/Studies/DetailsPage/StudyDetails?Study=syn5550404
#
# Metadata: https://www.synapse.org/#!Synapse:syn29855549
# Individual metadata: https://www.synapse.org/#!Synapse:syn23277389
# Filtered counts: https://www.synapse.org/#!Synapse:syn27024951
# Biomart gene conversion: https://www.synapse.org/#!Synapse:syn27024953
# TODO temporary: use harmonized/corrected data from syn66639062

DownloadData_Mayo <- function(metadata_only = FALSE) {
  synIDs <- list("individual_metadata" = list(id = "syn66639062", version = 1),
                 "biospecimen_metadata" = list(id = "syn20827192", version = 13),
                 "assay_metadata" = list(id = "syn20827193", version = 4),
                 "metrics" = list(id = "syn21544637", version = 1),
                 "counts" = list(id = "syn21544635", version = 1))

  if (metadata_only) {
    synIDs <- synIDs[1:4]
  }

  files <- DownloadFromSynapse(synIDs, dir_mayo_raw)
  return(files)
}


## MSBB ------------------------------------------------------------------------
# Bulk RNA seq data from the Mount Sinai Brain Bank Study:
# https://adknowledgeportal.synapse.org/Explore/Studies/DetailsPage/StudyDetails?Study=syn3159438
#
# Metadata: https://www.synapse.org/#!Synapse:syn29855570
# Individual metadata: https://www.synapse.org/#!Synapse:syn6101474
# Filtered counts: https://www.synapse.org/#!Synapse:syn27068754
# Biomart gene conversion: https://www.synapse.org/#!Synapse:syn27068755
# TODO temporary: Use harmonized/corrected data from syn66639063

DownloadData_MSBB <- function(metadata_only = FALSE) {
  synIDs <- list("individual_metadata" = list(id = "syn66639063", version = 1),
                 "biospecimen_metadata" = list(id = "syn21893059", version = 14),
                 "assay_metadata" = list(id = "syn22447899", version = 6),
                 "metrics" = list(id = "syn21544666", version = 1),
                 "counts" = list(id = "syn21544664", version = 1))

  if (metadata_only) {
    synIDs <- synIDs[1:4]
  }

  files <- DownloadFromSynapse(synIDs, dir_msbb_raw)
  return(files)
}


## ROSMAP ----------------------------------------------------------------------
# Bulk RNA seq data from the ROSMAP study:
# https://adknowledgeportal.synapse.org/Explore/Studies/DetailsPage/StudyDetails?Study=syn3219045
#
# Metadata: https://www.synapse.org/#!Synapse:syn29855598
# Individual metadata: https://www.synapse.org/#!Synapse:syn3191087
# Filtered counts: https://www.synapse.org/#!Synapse:syn26967451
# Biomart gene conversion: https://www.synapse.org/#!Synapse:syn26967452
# TODO Temporary: use harmonized/corrected data from syn66639064

DownloadData_ROSMAP <- function(metadata_only = FALSE) {
  synIDs <- list("individual_metadata" = list(id = "syn66639064", version = 2),
                 "biospecimen_metadata" = list(id = "syn21323366", version = 19),
                 "assay_metadata" = list(id = "syn21088596", version = 5),
                 "metrics1" = list(id = "syn22283384", version = 4),
                 "metrics2" = list(id = "syn22301603", version = 4),
                 "metrics3" = list(id = "syn22314232", version = 4),
                 "metrics4" = list(id = "syn25817663", version = 4),
                 "counts1" = list(id = "syn22283382", version = 4),
                 "counts2" = list(id = "syn22301601", version = 4),
                 "counts3" = list(id = "syn22314230", version = 4),
                 "counts4" = list(id = "syn25817661", version = 4))

  if (metadata_only) {
    synIDs <- synIDs[1:7]
  }

  files <- DownloadFromSynapse(synIDs, dir_rosmap_raw)
  return(files)
}


## Generic bulk functions ------------------------------------------------------
# These functions all work on Mayo, MSBB, and ROSMAP since the files all come
# from the harmonization effort and are in the same format

ReadMetadata_BulkData <- function(dataset, files) {
  ind <- read.csv(files$individual_metadata$path)
  bio <- read.csv(files$biospecimen_metadata$path) |>
    subset((is.na(exclude) | exclude == FALSE) & assay == "rnaSeq") |>
    select(individualID, specimenID, tissue)
  assay <- read.csv(files$assay_metadata$path) |>
    select(specimenID, RIN, any_of(c("sequencingBatch", "flowcell")))

  if (dataset == "Mayo") {
    assay$batch <- assay$flowcell
  } else {
    assay$batch <- assay$sequencingBatch
  }

  assay$batch <- ifelse(is.na(assay$batch), "unknown", assay$batch)

  if (dataset == "ROSMAP") {
    metrics <- lapply(paste0("metrics", 1:4), function(m_name) {
      read.delim(files[[m_name]]$path) |>
        select(sample, contains("_PCT_"))
    })

    metrics <- do.call(rbind, metrics)
  } else {
    metrics <- read.delim(files$metrics$path) |>
      select(sample, contains("_PCT_"))
  }

  metadata <- ind |>
    merge(bio) |>
    merge(assay) |>
    merge(metrics, by.x = "specimenID", by.y = "sample") |>
    mutate(
      tissue = case_match(
        tissue,
        # Mayo
        "cerebellum" ~ "CBE",
        "temporal cortex" ~ "TCX",
        # MSBB
        "frontal pole" ~ "FP",
        "inferior frontal gyrus" ~ "IFG",
        "parahippocampal gyrus" ~ "PHG",
        "superior temporal gyrus" ~ "STG",
        # ROSMAP
        "dorsolateral prefrontal cortex" ~ "DLPFC",
        "Head of caudate nucleus" ~ "ACC",
        "posterior cingulate cortex" ~ "PCC",
        .default = tissue
      ),
      batch = paste0(tissue, "_", batch)
    )

  # Move a singleton batch in ROSMAP to batch 0
  if (dataset == "ROSMAP") {
    metadata <- metadata |>
      mutate(batch = case_match(batch,
                                "DLPFC_0, 6, 7" ~ "DLPFC_0",
                                .default = batch))
  }

  # Reclassify samples using the criteria from the Diverse Cohorts phenotype
  # harmonization:
  #   AD: Braak >= 4 and [CERAD = probable AD or definite AD, or Thal >= 2 (Mayo only)]
  #   CT: Braak <= 3 and [CERAD = normal or possible AD, or Thal < 2 (Mayo only)]
  #   OTHER: all other samples
  # I expand the OTHER diagnosis into two more groups:
  #   PATH_HIGH_CERAD: Braak <= 3 and [CERAD = probable AD or definite AD, or Thal >= 2 (Mayo only)]
  #   PATH_HIGH_BRAAK: Braak >= 4 and [CERAD = normal or possible AD, or Thal < 2 (Mayo only)]

  if (dataset == "Mayo") {
    # Mayo samples do not have CERAD values so we use Thal >= 2 for AD. In the
    # event of NA values for either Braak or Thal, the diagnosis already assigned
    # by Mayo contributors will stay as-is. Some PATH_AGE samples are affected
    # by this but since it's unclear what the pathology is we leave that diagnosis
    # as-is for those samples. We also leave the diagnosis of PSP as-is down below.
    renames <- c("Alzheimer Disease" = "AD", "control" = "CT",
                 "pathological aging" = "PATH_AGE",
                 "progressive supranuclear palsy" = "PSP")
    metadata <- metadata |>
      mutate(
        diagnosis = renames[diagnosis],
        ad_cerad = case_match(amyThal,
          paste("Phase", 2:5) ~ TRUE,
          c("missing or unknown", NA) ~ NA,
          .default = FALSE
        ),
        # Forces PSP to be left alone below
        ad_cerad = ifelse(diagnosis == "PSP", NA, ad_cerad)
      )
  } else {
    # TODO
    metadata$ad_cerad <- case_match(metadata$amyCerad,
      c("Moderate/Probable/C2", "Frequent/Definite/C3") ~ TRUE,
      c("missing or unknown", NA) ~ NA,
      .default = FALSE
    )
  }

  if (!("diagnosis" %in% colnames(metadata))) {
    metadata$diagnosis <- NA
  }

  metadata <- metadata |>
    mutate(
      high_braak = case_match(Braak,
                              paste("Stage", c("IV", "V", "VI")) ~ TRUE,
                              c("missing or unknown", NA) ~ NA,
                              .default = FALSE),
      # Re-code diagnosis based on CERAD/Braak scores
      diagnosis = case_when(
        is.na(ad_cerad) | is.na(high_braak) ~ diagnosis,
        ad_cerad & high_braak ~ "AD",
        !ad_cerad & !high_braak ~ "CT",
        !ad_cerad & high_braak ~ "PATH_HIGH_BRAAK",
        ad_cerad & !high_braak ~ "PATH_HIGH_CERAD"
      )
    )

  # Drop samples with RIN < 3. The threshold of 3 was determined by ranking the
  # RIN values in each data set and looking for the inflection point where RIN
  # dropped rapidly. All Mayo samples are above 5, but both MSBB and ROSMAP
  # have an inflection point at ~3.
  metadata$RIN[is.na(metadata$RIN)] <- 0

  print(str_glue("{sum(metadata$RIN < 3)} sample(s) will be removed from ",
                 "{dataset} due to low RIN."))
  metadata <- subset(metadata, RIN >= 3)

  # Necessary because the column names of the counts matrix get converted this
  # way automatically
  metadata$specimenID <- make.names(metadata$specimenID)

  # MSBB has a few resequenced samples that need to be removed, and there are
  # only a small number of "prefrontal cortex" samples. These are removed as
  # well.
  if (dataset == "MSBB") {
    metadata <- subset(metadata, !grepl("resequenced", specimenID) &
                         tissue != "prefrontal cortex")
  }

  covariates <- metadata
  metadata <- select(metadata, specimenID, diagnosis, tissue)

  return(list("metadata" = metadata, "covariates" = covariates))
}

ReadCounts_BulkData <- function(files, metadata) {
  counts <- read.table(files[["counts"]]$path, header = TRUE, row.names = 1)
  rownames(counts) <- str_replace(rownames(counts), "\\.[0-9]+", "")

  # Counts matrix has a few rows of statistics before genes start, remove them
  counts <- counts[grepl("ENSG", rownames(counts)), ]

  return(counts)
}

ReadCounts_ROSMAP <- function(files, metadata) {
  counts <- lapply(paste0("counts", 1:4), function(c_name) {
    read.table(files[[c_name]]$path, header = TRUE, row.names = 1)
  })

  all_genes <- lapply(counts, rownames) |> unlist() |> unique()
  counts <- lapply(counts, function(c_mat) {
    c_mat[all_genes, ]
  })

  counts <- do.call(cbind, counts)

  rownames(counts) <- str_replace(rownames(counts), "\\.[0-9]+", "")

  # Counts matrix has a few rows of statistics before genes start, remove them
  counts <- counts[grepl("ENSG", rownames(counts)), ]

  return(counts)
}


# Per-batch outlier detection via PCA. Each batch in the data is unique to one
# tissue, so data is actually split by tissue + sequencing batch.
#
# Arguments:
#   covariates = a data.frame of covariates
#   counts = a matrix of counts, with columns corresponding to specimenIDs in
#            the covariates data.frame
#   sd_threshold = how many standard deviations from mean must a sample be to
#                  be considered an outlier
#   do_plot = whether to plot the PCA of counts, colored by outlier status
#
# Returns:
#   a vector containing the sample names of outliers
FindOutliers_BulkData <- function(dataset, covariates, counts, sd_threshold = 4,
                                  do_plot = FALSE) {
  # Define how to split the data into batches for batch-specific outlier
  # detection. On a PCA plot of all samples, Mayo is distinctly split by tissue
  # but not sequencing batch, MSBB samples split by batch but certain batches
  # group together, and ROSMAP is split by batch.
  covariates$batch <- switch(dataset,
                             "Mayo" = covariates$tissue,
                             "MSBB" = covariates$batch,
                             "ROSMAP" = covariates$batch)

  # MSBB batches cluster by the second half of their batch name + tissue, rather
  # than separating by batch completely
  if (dataset == "MSBB") {
    covariates$batch <- str_replace(covariates$batch, "_[A-Z][0-9]+r?", "_")
  }

  # Ensure covariates are in the same order as counts
  rownames(covariates) <- covariates$specimenID
  covariates <- covariates[colnames(counts), ]

  gene_info <- read.csv(file_gene_list)

  # Find outliers by batch
  pca_results <- sageRNAUtils::find_pca_outliers_by_group(
    data = sageRNAUtils::simple_log2norm(as.matrix(counts)),
    pca_group = "batch",
    n_sds = sd_threshold,
    metadata = covariates,
    sample_colname = "specimenID",
    gene_info = gene_info,
    min_group_size = 20
  )

  if (do_plot) {
    plts <- lapply(pca_results$group_results, function(res) {
      sageRNAUtils::plot_pca_outliers(res$pca_df,
                                      res$pc1_threshold,
                                      res$pc2_threshold,
                                      print_plot = FALSE)
    })
    print(Reduce("+", plts))
  }

  return(pca_results$outliers)
}


FindSexMismatches_BulkData <- function(dataset, covariates, counts,
                                       y_expr_threshold = 2,
                                       do_plot = FALSE) {
  mismatches <- sageRNAUtils::find_sex_mismatches(
    covariates,
    sageRNAUtils::simple_log2norm(counts),
    y_expr_threshold = y_expr_threshold
  )

  if (do_plot) {
    plts <- sageRNAUtils::plot_sex_mismatch_results(
      mismatches$sex_check_df, mismatches$y_expr_threshold, print_plot = FALSE
    )
    print(plts[[1]] + plts[[2]])
  }

  return(mismatches$mismatches)
}
